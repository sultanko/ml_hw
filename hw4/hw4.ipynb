{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "#from IPython.display import display, clear_output\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score as sk_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/chips.txt', header=None, names=['X', 'Y', 'Class'])\n",
    "data = data.sample(frac=1, random_state=0)\n",
    "xs = data[['X', 'Y']].values\n",
    "ys = data['Class'].values\n",
    "\n",
    "#arr = np.genfromtxt('data/chips.txt', delimiter=',')\n",
    "#xs, ys = arr[:,:2].copy(), np.int32(arr[:, 2:].ravel())\n",
    "xs = StandardScaler().fit_transform(xs)\n",
    "# ys = 2 * ys - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(predicted, true):\n",
    "    tp = ((predicted == true) * (predicted == 1)).sum()\n",
    "    tn = ((predicted == true) * (predicted != 1)).sum()\n",
    "    fp = ((predicted != true) * (predicted == 1)).sum()\n",
    "    fn = ((predicted != true) * (predicted != 1)).sum()\n",
    "    p = tp*1.0/max(1, tp+fp)\n",
    "    r = tp*1.0/max(1, tp+fn)\n",
    "    return (2*p*r/max(1, p+r), tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_f1Nmatrix(t):\n",
    "    print(\"confusion matrix\")\n",
    "    print(\"    T   F\")\n",
    "    print(\"P \", t[1], t[3])\n",
    "    print(\"N \", t[4], t[2])\n",
    "    print(\"f1_score = \", t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    p = np.arange(0, X.shape[0])\n",
    "    np.random.shuffle(p)\n",
    "    return (X[p], y[p])\n",
    "np.random.seed(42)\n",
    "#xs, ys = shuffle(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot1 = data.plot(kind='scatter', x='X', y='Y', c='Class', grid=True)\n",
    "#plot1.set_facecolor(\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, part=10):\n",
    "    p = X.shape[0] // part\n",
    "    return X[p:], y[p:], X[:p], y[:p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_function(x):\n",
    "    return np.array([x[0], x[1], x[0]**2+x[1]**2, x[0]**2+2*x[0]*x[1]+x[1]**2])\n",
    "    #return np.array([x[0], x[1], (x[0]**2 + x[1]**2) ** 0.5, np.arctan2(x[0], x[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "def kf_cross_validation(regressor, xs, ys, n_fold=10, kf=None, **params):\n",
    "    measure = lambda x, y: f1_score(x, y)[0]\n",
    "    kf_sum = 0\n",
    "    f1_scores = []\n",
    "    if kf is None:\n",
    "        kf = KFold(len(xs), n_fold, True, 0)\n",
    "    fold_num = 0\n",
    "    P = 100\n",
    "    for train_i, test_i in kf:\n",
    "        regressor.fit(xs[train_i], ys[train_i], **params)\n",
    "        predicted = regressor.predict(xs[test_i])\n",
    "        meas = measure(predicted, ys[test_i])\n",
    "        f1_scores.append(meas*P)\n",
    "        kf_sum += meas\n",
    "        fold_num += 1\n",
    "        # print(\"Fold {} done, measure = {}\".format(fold_num, meas))\n",
    "    return (kf_sum/len(kf), np.array(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_SGD(BaseEstimator):\n",
    "    def __init__(self, C, lr=0.01, eps=1e-5, iters=100, phi=None):\n",
    "        self.phi = phi\n",
    "        self.C = C\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.iters = iters\n",
    "        \n",
    "    def get_params(self, deep=False):\n",
    "        \n",
    "        return {\"C\": self.C,\n",
    "                \"phi\": self.phi,\n",
    "                \"lr\": self.lr,\n",
    "                \"eps\": self.eps,\n",
    "                \"iters\": self.iters}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.C = params[\"C\"]\n",
    "        self.phi = params[\"phi\"]\n",
    "        self.lr = params[\"lr\"]\n",
    "        self.eps = params[\"eps\"]\n",
    "        self.iters = params[\"iters\"]\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        #K(x1, x2)=<phi(x1), phi(x2)>        \n",
    "        if self.phi is not None:\n",
    "            X = np.apply_along_axis(self.phi, 1, X)\n",
    "        teta = 1.0 / (2 * self.C)\n",
    "        Y = 2 * Y - 1\n",
    "        n = X.shape[0]\n",
    "        dim = X.shape[1]        \n",
    "\n",
    "        last_obj= -np.inf\n",
    "        t = self.lr\n",
    "        lr = 1.\n",
    "\n",
    "        #solve minimization problem\n",
    "        w = np.zeros(dim)\n",
    "        w0 = 0\n",
    "        for it in range(self.iters):\n",
    "            for x,y in zip(X, Y):\n",
    "                margin = y * (np.dot(x, w) - w0)\n",
    "                sl = np.maximum(1 - margin, 0)\n",
    "                w = w - self.lr * (-sl * y * x + 2 * teta * w)\n",
    "                w0 = w0 - self.lr * (sl * y)\n",
    "            margin = (np.dot(X, w) - w0) * Y\n",
    "            cur_obj = np.maximum(1 - margin, 0).sum() + teta * np.dot(w, w)\n",
    "            if abs(last_obj - cur_obj) < self.eps:                \n",
    "                break\n",
    "            last_obj = cur_obj\n",
    "\n",
    "            lr = lr*(1+lr*t*it)**-1\n",
    "        self.w, self.w0 = w, w0                \n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.phi is not None:\n",
    "            x = np.apply_along_axis(self.phi, 1, x)\n",
    "                    \n",
    "        return (np.ndarray.astype(np.sign(np.dot(x, self.w) - self.w0), np.int32) + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No kernel, C = 100\n",
      "confusion matrix\n",
      "    T   F\n",
      "P  17 21\n",
      "N  39 41\n",
      "f1_score =  0.262250453721\n"
     ]
    }
   ],
   "source": [
    "print(\"No kernel, C = 100\")\n",
    "svm = SVM_SGD(C = 100)\n",
    "svm.fit(xs, ys)\n",
    "pr = svm.predict(xs)\n",
    "print_f1Nmatrix(f1_score(pr, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi (x, y, x**2+y**2, 2xy)\n",
      "C = 1\n",
      "f1_score = 0.795621616945\n",
      "--------------------------------------------------\n",
      "C = 2\n",
      "f1_score = 0.811030472795\n",
      "--------------------------------------------------\n",
      "C = 10\n",
      "f1_score = 0.811030472795\n",
      "--------------------------------------------------\n",
      "C = 100\n",
      "f1_score = 0.816177531619\n",
      "--------------------------------------------------\n",
      "C = 1000\n",
      "f1_score = 0.816177531619\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"phi (x, y, x**2+y**2, 2xy)\")\n",
    "for C in [1, 2, 10, 100, 1000]:\n",
    "    svm = SVM_SGD(C = C, phi = space_function )\n",
    "    print(\"C =\", C)    \n",
    "    print(\"f1_score =\", kf_cross_validation(svm, xs, ys)[0])        \n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = 10\n",
    "best_f1_sc = 0\n",
    "for ic in range(5, 15):\n",
    "    svm = SVM_SGD(C = ic, phi = space_function )\n",
    "    f1_sc_t = kf_cross_validation(svm, xs, ys)[0];\n",
    "    if (f1_sc_t > best_f1_sc):\n",
    "        best_c = ic\n",
    "        best_f1_sc = f1_sc_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset, C =  5\n",
      "confusion matrix\n",
      "    T   F\n",
      "P  49 9\n",
      "N  51 9\n",
      "f1_score =  0.844827586207\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Full dataset, C = \", best_c)\n",
    "svm = SVM_SGD(C = best_c, phi = space_function)\n",
    "svm.fit(xs, ys)\n",
    "prediction_svm = svm.predict(xs)\n",
    "print_f1Nmatrix(f1_score(prediction_svm, ys))\n",
    "print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wilcoxon(x, y):\n",
    "    assert len(x) == len(y)\n",
    "    d = x - y\n",
    "    d = np.compress(np.not_equal(d, 0), d, axis=-1)\n",
    "    count = len(d)  \n",
    "    r = np.sort(abs(d))    \n",
    "    nr = len(r)\n",
    "    for i in range(0, nr):\n",
    "        j = i\n",
    "        while j < nr and r[i] == r[j]:\n",
    "            j += 1\n",
    "        r[i:j] = (j*(j-1)/2 - i*(i-1)/2) / (j - i)    \n",
    "    W = sum(r * np.sign(d))\n",
    "    z_score = W / np.sqrt(nr*(nr+1)*(2*nr+1)/6)\n",
    "    return W, z_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN f1_score: [ 73.68421053  87.5         80.          73.68421053  54.54545455  70.\n",
      "  66.66666667]\n",
      "KNN f1_score: 0.722972203235\n",
      "KNN f1_score: [ 73.68421053  87.5         93.33333333  84.21052632  66.66666667\n",
      "  77.77777778  90.        ]\n",
      "SVM f1_score: 0.818817878028\n"
     ]
    }
   ],
   "source": [
    "import knn\n",
    "n_fold = 7\n",
    "kf = KFold(len(xs), n_fold, True, 7)\n",
    "\n",
    "knn = knn.KNN()\n",
    "svm = SVM_SGD(C = best_c, phi = space_function)\n",
    "\n",
    "f1_knn, f1_scoresKnn = kf_cross_validation(knn, xs, ys, kf=kf, k=3, weight_f='uniform', metric_f='l2')\n",
    "print(\"KNN f1_score:\", f1_scoresKnn)\n",
    "print(\"KNN f1_score:\", f1_knn)\n",
    "f1_svm, f1_scoresSvm = kf_cross_validation(svm, xs, ys, kf=kf)\n",
    "print(\"KNN f1_score:\", f1_scoresSvm)\n",
    "print(\"SVM f1_score:\", f1_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10.0, 1.3483997249264841)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Wilcoxon\")\n",
    "wilcoxon(f1_scoresSvm, f1_scoresKnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pValue\n",
      "x^2 = 15.4504485119\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "pValueTable =[\n",
    "[ 0, 0.995,0.99,0.975,   0.95, 0.9,  0.1,  0.05,0.025,0.01,0.005],\n",
    "[ 1,  0,0 ,0.001, 0.004 ,0.016,2.706, 3.841, 5.024, 6.635, 7.879],\n",
    "[ 2, 0.01 , 0.02 ,0.051,0.103,0.211,4.605 ,5.991  ,7.378  ,9.21   ,10.597],\n",
    "[ 3, 0.072, 0.115,0.216,0.352,0.584,6.251 ,7.815  ,9.348  ,11.345 ,12.838],\n",
    "[ 4, 0.207, 0.297,0.484,0.711,1.064,7.779 ,9.488  ,11.143 ,13.277 ,14.86],\n",
    "[ 5, 0.412, 0.554,0.831,1.145,1.61 ,9.236 ,11.07  ,12.833 ,15.086 ,16.75],\n",
    "[ 6, 0.676, 0.872,1.237,1.635,2.204,10.645, 12.592, 14.449, 16.812, 18.548],\n",
    "[ 7, 0.989, 1.239,1.69 ,2.167,2.833,12.017, 14.067, 16.013, 18.475, 20.278],\n",
    "[ 8, 1.344, 1.646,2.18 ,2.733,3.49 ,13.362, 15.507, 17.535, 20.09 , 21.955],\n",
    "[ 9, 1.735, 2.088,2.7,  3.325,4.168,14.684, 16.919, 19.023, 21.666, 23.589],\n",
    "[ 10, 2.156,2.558,3.247,3.94 ,4.865,15.989, 18.307, 20.483, 23.209, 25.188],\n",
    "[ 11, 2.603,3.053,3.816,4.575,5.578,17.275, 19.675, 21.92 ,24.725 ,26.757]]\n",
    "\n",
    "def chiSquare(exp, obs):\n",
    "    x2 = ((obs-exp)**2/exp).sum()\n",
    "    print(\"x^2 =\", x2)\n",
    "    \n",
    "    r = len(exp) - 1\n",
    "    j = 1\n",
    "    while (j < len(pValueTable[r]) - 1 and x2 > pValueTable[r][j]):\n",
    "        j += 1\n",
    "    return pValueTable[0][j]\n",
    "\n",
    "print(\"pValue\")\n",
    "print(chiSquare(f1_scoresKnn, f1_scoresSvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
